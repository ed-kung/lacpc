{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bc294f0-ff31-46a4-9869-3df2f6eaeb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "from unidecode import unidecode\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "sys.path.append('../python')\n",
    "\n",
    "import text_tools as tt\n",
    "\n",
    "with open('../../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "DOCID = \"lamunicipalcode\"\n",
    "FILENAME = f\"../../raw_data/{DOCID}.html\"\n",
    "CHUNK_SIZE = config['CHUNK_SIZE']\n",
    "CHUNK_OVERLAP = config['CHUNK_OVERLAP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0010432f-ae62-4cdd-93d2-5596fe25986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the HTML file\n",
    "\n",
    "with open(FILENAME, 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "soup = BeautifulSoup(content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2eb8291-646f-4146-a1d7-136c84ee74a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data into chapters, articles, sections, and passages\n",
    "\n",
    "divs = soup.find_all('div', class_='rbox')\n",
    "data = []\n",
    "text_order = 0\n",
    "for div in divs:\n",
    "    class_ = div.attrs.get('class')\n",
    "    div_id = div.attrs.get('id')\n",
    "    myid = DOCID + '_' + div_id\n",
    "    text = div.get_text('\\n')\n",
    "    text = unidecode(text)\n",
    "    text = re.sub(r'\\s+',' ',text).strip()\n",
    "\n",
    "    if len(text)==0:\n",
    "        continue\n",
    "\n",
    "    if (('Chapter' in class_) and div.find('a')):  # div is a chapter title\n",
    "        item_type = 'chapter_title'\n",
    "        level = -2\n",
    "    elif (('Article' in class_) and div.find('a')): # div is an article title\n",
    "        item_type = 'article_title'\n",
    "        level = -1\n",
    "    elif (('Section' in class_) and div.find('a')): # div is a section title\n",
    "        item_type = 'section_title'\n",
    "        level = 0\n",
    "    else:\n",
    "        item_type = 'passage'\n",
    "        level = 1\n",
    "        for l in range(2,8):\n",
    "            subdivs = div.find_all('div', class_=f'L{l}')\n",
    "            if (subdivs is not None) and (len(subdivs)>0):\n",
    "                level = l\n",
    "    data.append({\n",
    "        'id': myid,\n",
    "        'parent_id': '',\n",
    "        'doc_id': DOCID, \n",
    "        'item_type': item_type,\n",
    "        'item_level': level,\n",
    "        'text_order': text_order,\n",
    "        'text': text,\n",
    "        'sibling_left_id': '',\n",
    "        'sibling_right_id': '',\n",
    "        'first_child_id': '',\n",
    "        'next_id': '',\n",
    "        'prev_id': ''\n",
    "    })\n",
    "    text_order+=1\n",
    "\n",
    "data = pd.DataFrame.from_dict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab30f55-8687-4aba-8f5a-2ea3073424af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0... 128... 256... 384... 512... 640... 768... 896... 1024... 1152... 1280... 1408... 1536... 1664... 1792... 1920... 2048... 2176... 2304... 2432... 2560... 2688... 2816... 2944... 3072... 3200... 3328... 3456... 3584... 3712... 3840... 3968... 4096... 4224... 4352... 4480... 4608... 4736... 4864... 4992... 5120... 5248... 5376... 5504... 5632... 5760... 5888... 6016... 6144... 6272... 6400... 6528... 6656... 6784... 6912... 7040... 7168... 7296... 7424... 7552... 7680... 7808... 7936... 8064... 8192... 8320... 8448... 8576... 8704... 8832... 8960... 9088... 9216... 9344... 9472... 9600... 9728... 9856... 9984... 10112... 10240... 10368... 10496... 10624... 10752... 10880... 11008... 11136... 11264... 11392... 11520... 11648... 11776... 11904... 12032... 12160... 12288... 12416... 12544... 12672... 12800... 12928... 13056... 13184... 13312... 13440... 13568... 13696... 13824... 13952... 14080... 14208... 14336... 14464... 14592... 14720... 14848... 14976... 15104... 15232... 15360... 15488... 15616... 15744... 15872... 16000... 16128... 16256... 16384... 16512... 16640... 16768... 16896... 17024... 17152... 17280... 17408... 17536... 17664... 17792... 17920... 18048... 18176... 18304... 18432... 18560... 18688... 18816... 18944... 19072... 19200... 19328... 19456... 19584... 19712... 19840... 19968... 20096... 20224... 20352... 20480... 20608... 20736... 20864... 20992... 21120... 21248... 21376... 21504... 21632... 21760... 21888... 22016... 22144... 22272... 22400... 22528... 22656... 22784... 22912... 23040... 23168... 23296... 23424... 23552... 23680... 23808... 23936... 24064... 24192... 24320... 24448... 24576... 24704... 24832... 24960... 25088... 25216... 25344... 25472... 25600... 25728... 25856... 25984... 26112... 26240... 26368... 26496... 26624... 26752... 26880... 27008... 27136... 27264... 27392... 27520... 27648... 27776... 27904... 28032... 28160... 28288... 28416... 28544... 28672... 28800... 28928... 29056... 29184... 29312... 29440... 29568... 29696... 29824... 29952... 30080... 30208... 30336... 30464... 30592... 30720... 30848... 30976... 31104... 31232... 31360... 31488... 31616... 31744... 31872... 32000... 32128... 32256... 32384... 32512... 32640... 32768... 32896... 33024... 33152... 33280... 33408... 33536... 33664... 33792... 33920... 34048... 34176... 34304... 34432... 34560... 34688... 34816... 34944... 35072... 35200... 35328... 35456... 35584... 35712... 35840... 35968... 36096... 36224... 36352... 36480... 36608... 36736... 36864... 36992... 37120... 37248... 37376... 37504... 37632... 37760... 37888... 38016... 38144... 38272... 38400... 38528... 38656... 38784... 38912... 39040... 39168... 39296... 39424... 39552... 39680... 39808... 39936... 40064... 40192... 40320... 40448... 40576... 40704... 40832... 40960... 41088... 41216... 41344... 41472... 41600... 41728... 41856... 41984... 42112... 42240... 42368... 42496... 42624... 42752... 42880... 43008... 43136... 43264... 43392... 43520... 43648... 43776... 43904... 44032... 44160... 44288... 44416... 44544... 44672... 44800... 44928... 45056... 45184... 45312... 45440... 45568... 45696... 45824... 45952... 46080... 46208... 46336... 46464... 46592... 46720... 46848... 46976... 47104... 47232... 47360... 47488... 47616... 47744... 47872... 48000... 48128... 48256... 48384... 48512... 48640... 48768... 48896... 49024... 49152... 49280... 49408... 49536... 49664... 49792... 49920... 50048... 50176... 50304... 50432... 50560... 50688... 50816... 50944... 51072... 51200... 51328... 51456... 51584... 51712... 51840... 51968... 52096... 52224... 52352... 52480... 52608... 52736... 52864... Elapsed time: 2.23 minutes\n"
     ]
    }
   ],
   "source": [
    "# Find parents by looking backwards to the first previous item with lower level\n",
    "# Find siblings by looking left and right at same level\n",
    "t0 = time.time()\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    if (idx%128)==0:\n",
    "        print(f\"{idx}... \", end='')\n",
    "    \n",
    "    parent_found = False\n",
    "    my_level = row['item_level']\n",
    "    j = idx-1\n",
    "    while (not parent_found and j>=0):\n",
    "        if data.loc[j,'item_level'] < my_level:\n",
    "            parent_found = True\n",
    "            data.loc[idx,'parent_id'] = data.loc[j,'id']\n",
    "        j=j-1\n",
    "\n",
    "    done = False\n",
    "    my_level = row['item_level']\n",
    "    j = idx+1\n",
    "    while (not done and j<len(data)):\n",
    "        if data.loc[j,'item_level'] < my_level:\n",
    "            done = True\n",
    "        elif data.loc[j,'item_level'] > my_level:\n",
    "            done = True\n",
    "            data.loc[idx,'first_child_id'] = data.loc[j,'id']\n",
    "        j=j+1\n",
    "\n",
    "    if idx>0:\n",
    "        j = idx-1\n",
    "        data.loc[idx,'prev_id'] = data.loc[j,'id']\n",
    "        if data.loc[j,'item_level']==my_level:\n",
    "            data.loc[idx,'sibling_left_id'] = data.loc[j,'id']\n",
    "\n",
    "    if idx<len(data)-1:\n",
    "        j = idx+1\n",
    "        data.loc[idx,'next_id'] = data.loc[j,'id']\n",
    "        if data.loc[j,'item_level']==my_level:\n",
    "            data.loc[idx,'sibling_right_id'] = data.loc[j,'id']\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"Elapsed time: {(t1-t0)/60:.2f} minutes\")\n",
    "            \n",
    "data = data.set_index('id')\n",
    "data.to_csv(f\"../../intermediate_data/{DOCID}_main.csv\")\n",
    "data.to_pickle(f\"../../intermediate_data/{DOCID}_main.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
