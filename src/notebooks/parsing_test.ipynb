{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bc294f0-ff31-46a4-9869-3df2f6eaeb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "from unidecode import unidecode\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "with open('../../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "FILENAME = \"../../raw_data/lamunicipalcode.html\"\n",
    "DOCID = \"lamunicipalcode\"\n",
    "CHUNK_SIZE = config['CHUNK_SIZE']\n",
    "CHUNK_OVERLAP = config['CHUNK_OVERLAP']\n",
    "\n",
    "import re\n",
    "\n",
    "BULLET_TYPES = [\n",
    "    r'^\\([ivx]+\\)',\n",
    "    r'^[ivx]+\\.',\n",
    "    r'^[0-9\\.]+',\n",
    "    r'^\\([0-9]+\\)',\n",
    "    r'^[A-Z]\\.',\n",
    "    r'^[a-z]\\.',\n",
    "    r'^\\([A-Z]\\)',\n",
    "    r'^\\([a-z]\\)',\n",
    "]\n",
    "\n",
    "def is_bullet(text):\n",
    "    for btype in BULLET_TYPES: \n",
    "        if re.match(btype, text):\n",
    "            return btype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0010432f-ae62-4cdd-93d2-5596fe25986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the HTML file\n",
    "\n",
    "with open(FILENAME, 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "soup = BeautifulSoup(content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2eb8291-646f-4146-a1d7-136c84ee74a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data into chapters, articles, sections, and passages\n",
    "\n",
    "chapter_id = ''\n",
    "article_id = ''\n",
    "section_id = ''\n",
    "passage_id = ''\n",
    "\n",
    "divs = soup.find_all('div', class_='rbox')\n",
    "data = []\n",
    "for div in divs:\n",
    "    class_ = div.attrs.get('class')\n",
    "    is_chapter = ('Chapter' in class_) and div.find('a')\n",
    "    is_article = ('Article' in class_) and div.find('a')\n",
    "    is_section = ('Section' in class_) and div.find('a')\n",
    "    div_id = div.attrs.get('id')\n",
    "    text = div.get_text('\\n')\n",
    "    text = unidecode(text)\n",
    "    text = re.sub(r'\\s+',' ',text).strip()\n",
    "    myid = DOCID + '_' + div_id\n",
    "    if is_chapter:\n",
    "        chapter_id = myid\n",
    "        article_id = ''\n",
    "        section_id = ''\n",
    "        passage_id = ''\n",
    "        item_type = 'chapter_title'\n",
    "    elif is_article:\n",
    "        article_id = myid\n",
    "        section_id = ''\n",
    "        passage_id = ''\n",
    "        item_type = 'article_title'\n",
    "    elif is_section:\n",
    "        section_id = myid\n",
    "        passage_id = ''\n",
    "        item_type = 'section_title'\n",
    "    else:\n",
    "        passage_id = myid\n",
    "        item_type = 'passage_text'\n",
    "    if len(text)>0:\n",
    "        data.append({\n",
    "            'id': myid,\n",
    "            'doc_id': DOCID, \n",
    "            'chapter_id': chapter_id, \n",
    "            'article_id': article_id, \n",
    "            'section_id': section_id, \n",
    "            'passage_id': passage_id,\n",
    "            'item_type': item_type,\n",
    "            'text': text\n",
    "        })\n",
    "\n",
    "data = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95189a-bde6-494f-b3fd-152a3433f567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "e7976876-ea2e-42dd-8ac6-5f47a1c6ef3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b) In any case in which a person is arrested for the violation of any provision of this Code, or any ordinance of this City, by any officer or employee of this City who is not a peace officer, but who has been authorized by ordinance pursuant to Penal Code Section 836.5 to make such arrests, and such person does not demand to be taken before a magistrate, such arresting officer or employee shall prepare a written notice to appear and release the person on the person's promise to appear as prescribed by Chapter 5C (commencing with Section 853.6) of the Penal Code. The provisions of such code shall thereafter apply with reference to any proceeding based upon the issuance of a written notice to appear pursuant to this authority.\n",
      "\n",
      "^\\([a-z]\\)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "BULLET_TYPES = [\n",
    "    r'^\\([ivx]+\\)',\n",
    "    r'^[ivx]+\\.',\n",
    "    r'^[0-9\\.]+',\n",
    "    r'^\\([0-9]+\\)',\n",
    "    r'^[A-Z]\\.',\n",
    "    r'^[a-z]\\.',\n",
    "    r'^\\([A-Z]\\)',\n",
    "    r'^\\([a-z]\\)',\n",
    "]\n",
    "\n",
    "def is_bullet(text):\n",
    "    for btype in BULLET_TYPES: \n",
    "        if re.match(btype, text):\n",
    "            return btype\n",
    "\n",
    "mytext = data.sample(1).reset_index().loc[0, 'text']\n",
    "print(mytext)\n",
    "print(\"\")\n",
    "print(is_bullet(mytext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "71a792b3-a2f1-4bff-bfe8-5c30b6ef26db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" Responsible Person \" means the owner and/or person in charge or control of the Vacant Structure.\n"
     ]
    }
   ],
   "source": [
    "mytext = data.sample(1).reset_index().loc[0,'text']\n",
    "print(mytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be866e5e-3855-45c9-861a-56330457020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data into chapters, articles, sections, and passages\n",
    "\n",
    "divs = soup.find_all('div', class_='rbox')\n",
    "\n",
    "chapter_data = []\n",
    "article_data = []\n",
    "section_data = []\n",
    "passage_data = []\n",
    "\n",
    "chapter_id = ''\n",
    "article_id = ''\n",
    "section_id = ''\n",
    "curr_text = ''\n",
    "\n",
    "for div in divs:\n",
    "    class_ = div.attrs.get('class')\n",
    "    is_chapter = ('Chapter' in class_) and div.find('a')\n",
    "    is_article = ('Article' in class_) and div.find('a')\n",
    "    is_section = ('Section' in class_) and div.find('a')\n",
    "    \n",
    "    if is_chapter or is_article or is_section:\n",
    "        passage_data.append({\n",
    "            'id': DOCID + '_' + div_id,\n",
    "            'doc_id': DOCID, \n",
    "            'chapter_id': chapter_id, \n",
    "            'article_id': article_id,\n",
    "            'section_id': section_id,\n",
    "            'passage_id': div_id,\n",
    "            'item_type': 'passage',\n",
    "            'text': curr_text\n",
    "        })\n",
    "        curr_text = ''\n",
    "    \n",
    "    div_id = div.attrs.get('id')\n",
    "    text = div.get_text('\\n').replace(u'\\xa0',' ')\n",
    "    text = re.sub(r'\\s+',' ',text).strip()\n",
    "    text = unidecode(text)\n",
    "    \n",
    "    if is_chapter:\n",
    "        chapter_id = div.find('a').attrs.get('id')\n",
    "        article_id = ''\n",
    "        section_id = ''\n",
    "        chapter_data.append({\n",
    "            'id': DOCID + '_' + chapter_id,\n",
    "            'doc_id': DOCID,\n",
    "            'chapter_id': chapter_id,\n",
    "            'item_type': 'chapter_title',\n",
    "            'text': text\n",
    "        })\n",
    "    elif is_article:\n",
    "        article_id = div.find('a').attrs.get('id')\n",
    "        section_id = ''\n",
    "        article_data.append({\n",
    "            'id': DOCID + '_' + article_id,\n",
    "            'doc_id': DOCID,\n",
    "            'chapter_id': chapter_id,\n",
    "            'article_id': article_id,\n",
    "            'item_type': 'article_title',\n",
    "            'text': text\n",
    "        })\n",
    "    elif is_section:\n",
    "        section_id = div.find('a').attrs.get('id')\n",
    "        section_data.append({\n",
    "            'id': DOCID + '_' + section_id,\n",
    "            'doc_id': DOCID,\n",
    "            'chapter_id': chapter_id,\n",
    "            'article_id': article_id,\n",
    "            'section_id': section_id,\n",
    "            'item_type': 'section_title',\n",
    "            'text': text\n",
    "        })\n",
    "    else:\n",
    "        curr_text += text + ' '\n",
    "\n",
    "passage_data.append({\n",
    "    'id': DOCID + '_' + div_id,\n",
    "    'doc_id': DOCID, \n",
    "    'chapter_id': chapter_id, \n",
    "    'article_id': article_id,\n",
    "    'section_id': section_id,\n",
    "    'passage_id': div_id,\n",
    "    'item_type': 'passage',\n",
    "    'text': curr_text\n",
    "})\n",
    "\n",
    "chapter_data = pd.DataFrame.from_dict(chapter_data)\n",
    "article_data = pd.DataFrame.from_dict(article_data)\n",
    "section_data = pd.DataFrame.from_dict(section_data)\n",
    "passage_data = pd.DataFrame.from_dict(passage_data)\n",
    "\n",
    "chapter_data.to_csv(\"../../intermediate_data/los_angeles_chapter_data.csv\", header=True, index=False)\n",
    "article_data.to_csv(\"../../intermediate_data/los_angeles_article_data.csv\", header=True, index=False)\n",
    "section_data.to_csv(\"../../intermediate_data/los_angeles_section_data.csv\", header=True, index=False)\n",
    "passage_data.to_csv(\"../../intermediate_data/los_angeles_passage_data.csv\", header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b361ef-4e6b-469e-910c-0a8a198b56ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0... 1000... 2000... 3000... 4000... 5000... "
     ]
    }
   ],
   "source": [
    "# Chunk the passages\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP\n",
    ")\n",
    "\n",
    "chunk_data = []\n",
    "for idx, row in passage_data.iterrows():\n",
    "    if (idx%1000==0):\n",
    "        print(f\"{idx}... \", end='')\n",
    "    text = row['text']\n",
    "    texts = text_splitter.create_documents([text])\n",
    "    chunk_id = 0\n",
    "    for tx in texts:\n",
    "        new_row = dict(row).copy()\n",
    "        new_row.pop('text')\n",
    "        new_row.pop('item_type')\n",
    "        new_row['id'] = new_row['id'] + f'_{chunk_id}'\n",
    "        new_row['chunk_id'] = chunk_id\n",
    "        new_row['item_type'] = 'passage_chunk'\n",
    "        new_row['text'] = tx.page_content\n",
    "        chunk_data.append(new_row)\n",
    "        chunk_id += 1\n",
    "        \n",
    "chunk_data = pd.DataFrame.from_dict(chunk_data)\n",
    "\n",
    "chunk_data.to_csv(\"../../intermediate_data/los_angeles_passage_chunk_data.csv\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
