{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d01772f0-abcf-4320-897e-a8762711d18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Subsection Text\n",
      "0      OFFICIAL \\n\\t\\t\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\tCITY OF L...\n",
      "1                         MUNICIPAL CODE\\n\\t\\t\\t\\t\\t\\t ™\n",
      "2                                        Seventh Edition\n",
      "3                                         www.lacity.org\n",
      "4                                   Ordinance No. 77,000\n",
      "...                                                  ...\n",
      "47159          Number Title Figure A Visibility Triangle\n",
      "47160  Number Title Number Title 1809.3 Stepped Found...\n",
      "47161  Number Title Number Title 193.02.1. Transfer S...\n",
      "47162  The following table lists cumulatively all ord...\n",
      "47163  Ord. No. Eff. Date Oper. Date Section(s) Affec...\n",
      "\n",
      "[47164 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Path to the HTML file\n",
    "file_path = '../../raw_data/lamunicipalcode.html'\n",
    "\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as municipal_code:\n",
    "    content = municipal_code.read()\n",
    "\n",
    "soup = BeautifulSoup(content, 'lxml')\n",
    "\n",
    "# Find chapters\n",
    "chapters = soup.find_all('div', class_='rbox Chapter')   \n",
    "chapter_data = []\n",
    "for chapter in chapters:\n",
    "    a_tag = chapter.find('a')\n",
    "    if a_tag:\n",
    "        chapter_id = a_tag.attrs['id']\n",
    "    chapter_text = chapter.get_text(separator=\" | \").strip()\n",
    "    \n",
    "    chapter_data.append({\n",
    "        'Chapter ID': chapter_id,\n",
    "        'Chapter Text': chapter_text\n",
    "    })\n",
    "    \n",
    "chapter_data = pd.DataFrame.from_dict(chapter_data)\n",
    "\n",
    "# Save chapter data to Week 6 directory\n",
    "output_directory = '../../intermediate_data/'\n",
    "chapter_data.to_csv(output_directory + \"chapter_data.csv\", header=True, index=False)\n",
    "\n",
    "# Find articles\n",
    "articles = soup.find_all('div', class_='Article toc-destination rbox')\n",
    "article_data = []\n",
    "for article in articles:\n",
    "    a_tag = article.find('a')\n",
    "    if a_tag:\n",
    "        article_id = a_tag.attrs['id']\n",
    "    article_text = article.get_text(separator=\" | \")\n",
    "    article_data.append({\n",
    "        'Article ID': article_id,\n",
    "        'Article Text': article_text\n",
    "    })\n",
    "\n",
    "article_data = pd.DataFrame.from_dict(article_data)\n",
    "\n",
    "# Save article data to Week 6 directory\n",
    "article_data.to_csv(output_directory + \"article_data.csv\", header=True, index=False)\n",
    "\n",
    "#Find Sections\n",
    "\n",
    "sections = soup.find_all('div', class_='Section toc-destination rbox')\n",
    "section_data = []\n",
    "for section in sections:\n",
    "    a_tag = section.find('a')\n",
    "    if a_tag:\n",
    "        section_id = a_tag.attrs['id']\n",
    "    section_text = section.get_text(separator=\" | \")  #i saw the difference thatadding the separator makes, why is that\n",
    "    section_data.append({\n",
    "        'Section ID': section_id,\n",
    "        'Section Text': section_text\n",
    "    })\n",
    "    \n",
    "section_data =  pd.DataFrame.from_dict(section_data)\n",
    "\n",
    "#Save section data to week 6 directory\n",
    "\n",
    "section_data.to_csv(output_directory + \"section_data.csv\", header=True, index=False)\n",
    "\n",
    "# Find subsections\n",
    "subsections = soup.find_all('div', class_='rbox Normal-Level')\n",
    "\n",
    "# Initialize a list to store subsection data\n",
    "subsection_data = []\n",
    "\n",
    "# Loop through each div to extract subsection content\n",
    "for subsection in subsections:\n",
    "    # Extract the text content of the subsection\n",
    "    subsection_text = subsection.get_text(separator=\" \").strip()\n",
    "    \n",
    "    # Append the text to the list\n",
    "    if subsection_text:\n",
    "        subsection_data.append({'Subsection Text': subsection_text})\n",
    "\n",
    "# Convert to DataFrame\n",
    "subsection_df = pd.DataFrame(subsection_data)\n",
    "\n",
    "# Define output directory\n",
    "output_directory = '../../intermediate_data/'\n",
    "\n",
    "# Save subsection data to Week 6 directory\n",
    "subsection_df.to_csv(output_directory + \"subsection_data.csv\", header=True, index=False)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(subsection_df)\n",
    "\n",
    "# Once we figure out subsections the next sub levels would be L2 and L3 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3faf3a61-7592-4b3a-9024-b774494bf84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sections DataFrame:\n",
      "        Section ID                                       Section Text\n",
      "0       JD_11.00.        SEC. 11.00.  PROVISIONS APPLICABLE TO CODE.\n",
      "1       JD_11.01.       SEC. 11.01.  DEFINITIONS AND INTERPRETATION.\n",
      "2       JD_11.02.    SEC. 11.02.  INCONSISTENT PERMITS AND LICENSES.\n",
      "3       JD_11.03.  SEC. 11.03.  POST WAR RENEWAL OF LICENSES OF C...\n",
      "4       JD_11.04.  SEC. 11.04.  DELINQUENT ACCOUNTS – UNCOLLECTIB...\n",
      "...           ...                                                ...\n",
      "5285  JD_200.124.              SEC. 200.124.  RULES AND REGULATIONS.\n",
      "5286  JD_200.125.                       SEC. 200.125.  SEVERABILITY.\n",
      "5287  JD_200.126.  SEC. 200.126.  NO CONFLICT WITH FEDERAL OR STA...\n",
      "5288  JD_200.127.                             SEC. 200.127.  SUNSET.\n",
      "5289  JD_200.201.  SEC. 200.201.  WAIVER OF FEES, FINES, AND PENA...\n",
      "\n",
      "[5290 rows x 2 columns]\n",
      "\n",
      "Subsections DataFrame:\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Path to the HTML file\n",
    "file_path = '../../raw_data/lamunicipalcode.html'\n",
    "\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as municipal_code:\n",
    "    content = municipal_code.read()\n",
    "\n",
    "soup = BeautifulSoup(content, 'lxml')\n",
    "\n",
    "# Find chapters\n",
    "chapters = soup.find_all('div', class_='rbox Chapter')   \n",
    "chapter_data = []\n",
    "for chapter in chapters:\n",
    "    a_tag = chapter.find('a')\n",
    "    if a_tag:\n",
    "        chapter_id = a_tag.attrs['id']\n",
    "    chapter_text = chapter.get_text(separator=\" | \").strip()\n",
    "    \n",
    "    chapter_data.append({\n",
    "        'Chapter ID': chapter_id,\n",
    "        'Chapter Text': chapter_text\n",
    "    })\n",
    "    \n",
    "chapter_data = pd.DataFrame.from_dict(chapter_data)\n",
    "\n",
    "# Save chapter data to Week 6 directory\n",
    "output_directory = '../../intermediate_data/'\n",
    "chapter_data.to_csv(output_directory + \"chapter_data.csv\", header=True, index=False)\n",
    "\n",
    "# Find articles\n",
    "articles = soup.find_all('div', class_='Article toc-destination rbox')\n",
    "article_data = []\n",
    "for article in articles:\n",
    "    a_tag = article.find('a')\n",
    "    if a_tag:\n",
    "        article_id = a_tag.attrs['id']\n",
    "    article_text = article.get_text(separator=\" | \")\n",
    "    article_data.append({\n",
    "        'Article ID': article_id,\n",
    "        'Article Text': article_text\n",
    "    })\n",
    "\n",
    "article_data = pd.DataFrame.from_dict(article_data)\n",
    "\n",
    "# Save article data to Week 6 directory\n",
    "article_data.to_csv(output_directory + \"article_data.csv\", header=True, index=False)\n",
    "\n",
    "# Find sections\n",
    "sections = soup.find_all('div', class_='Section toc-destination rbox')\n",
    "section_data = []\n",
    "for section in sections:\n",
    "    a_tag = section.find('a')\n",
    "    if a_tag:\n",
    "        section_id = a_tag.attrs['id']\n",
    "    section_text = section.get_text(separator=\" | \").strip()  # Adding separator to format the text\n",
    "    section_data.append({\n",
    "        'Section ID': section_id,\n",
    "        'Section Text': section_text\n",
    "    })\n",
    "\n",
    "# Convert section data to DataFrame\n",
    "section_df = pd.DataFrame(section_data)\n",
    "\n",
    "# Save section data to week 6 directory\n",
    "section_df.to_csv(output_directory + \"section_data.csv\", header=True, index=False)\n",
    "\n",
    "\n",
    "# Find subsections\n",
    "subsection_data = []\n",
    "sections = soup.find_all('div', class_='Section')\n",
    "for section in sections:\n",
    "    # Find all divs with class 'rbox Normal-Level' within the current section\n",
    "    subsections = section.find_all('div', class_='rbox Normal-Level')\n",
    "    for subsection in subsections:\n",
    "        subsection_text = subsection.get_text(separator=\" \").strip()\n",
    "        if subsection_text:\n",
    "            subsection_data.append({'Subsection Text': subsection_text})\n",
    "\n",
    "# Convert subsection data to DataFrame\n",
    "subsection_df = pd.DataFrame(subsection_data)\n",
    "\n",
    "# Save subsection data to week 6 directory\n",
    "subsection_df.to_csv(output_directory + \"subsection_data.csv\", header=True, index=False)\n",
    "\n",
    "# Print both DataFrames to verify\n",
    "print(\"Sections DataFrame:\\n\", section_df)\n",
    "print(\"\\nSubsections DataFrame:\\n\", subsection_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74045e16-3966-49bb-b81b-0261b062a8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsections DataFrame:\n",
      "    Section Title Subsection Text\n",
      "0     [Reserved]      [Reserved]\n",
      "1     [Reserved]      [Reserved]\n",
      "2     [Reserved]      [Reserved]\n",
      "3     [Reserved]      [Reserved]\n",
      "4     [Reserved]      [Reserved]\n",
      "5     [Reserved]      [Reserved]\n",
      "6     [Reserved]      [Reserved]\n",
      "7     [Reserved]      [Reserved]\n",
      "8     [Reserved]      [Reserved]\n",
      "9     [Reserved]      [Reserved]\n",
      "10    [Reserved]      [Reserved]\n",
      "11    [Reserved]      [Reserved]\n",
      "12    [Reserved]      [Reserved]\n",
      "13    [Reserved]      [Reserved]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Path to the HTML file\n",
    "file_path = '../../raw_data/lamunicipalcode.html'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as municipal_code:\n",
    "    content = municipal_code.read()\n",
    "\n",
    "soup = BeautifulSoup(content, 'lxml')\n",
    "\n",
    "# Find sections\n",
    "sections = soup.find_all('div', class_='Section toc-destination rbox')\n",
    "\n",
    "subsection_data = []\n",
    "\n",
    "for section in sections:\n",
    "    # Extract section title\n",
    "    section_title_tag = section.find('div')\n",
    "    section_title = section_title_tag.get_text(strip=True) if section_title_tag else ''\n",
    "    \n",
    "    # Find all nested divs (subsections) within the current section\n",
    "    subsections = section.find_all('div', recursive=True)\n",
    "    \n",
    "    # Iterate through subsections\n",
    "    for subsection in subsections:\n",
    "        # Ensure we're not processing the section title div\n",
    "        if subsection is not section_title_tag:\n",
    "            subsection_text = subsection.get_text(separator=\" \").strip()\n",
    "            if subsection_text:\n",
    "                subsection_data.append({\n",
    "                    'Section Title': section_title,\n",
    "                    'Subsection Text': subsection_text\n",
    "                })\n",
    "\n",
    "# Convert subsection data to DataFrame\n",
    "subsection_df = pd.DataFrame(subsection_data)\n",
    "\n",
    "# Save subsection data to intermediate_data directory\n",
    "output_directory = '../../intermediate_data/'\n",
    "subsection_df.to_csv(output_directory + \"subsection_data.csv\", header=True, index=False)\n",
    "\n",
    "# Print DataFrame to verify\n",
    "print(\"Subsections DataFrame:\\n\", subsection_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a17ae61-9d1e-4019-973d-a634158f47b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 29\u001b[0m\n\u001b[0;32m     23\u001b[0m section_data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSection ID\u001b[39m\u001b[38;5;124m'\u001b[39m: section_id,\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSection Title\u001b[39m\u001b[38;5;124m'\u001b[39m: section_title\n\u001b[0;32m     26\u001b[0m })\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Find all subsection divs within this section\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subsection_div \u001b[38;5;129;01min\u001b[39;00m \u001b[43msection_div\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all_next\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrbox Normal-Level\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     30\u001b[0m     subsection_text \u001b[38;5;241m=\u001b[39m subsection_div\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget_text(strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     31\u001b[0m     subsection_number_match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m([a-z]\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m'\u001b[39m, subsection_text)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\bs4\\element.py:592\u001b[0m, in \u001b[0;36mPageElement.find_all_next\u001b[1;34m(self, name, attrs, string, limit, **kwargs)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Find all PageElements that match the given criteria and appear\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;124;03mlater in the document than this PageElement.\u001b[39;00m\n\u001b[0;32m    580\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;124;03m:return: A ResultSet containing PageElements.\u001b[39;00m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    591\u001b[0m _stacklevel \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_stacklevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_elements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\bs4\\element.py:841\u001b[0m, in \u001b[0;36mPageElement._find_all\u001b[1;34m(self, name, attrs, string, limit, generator, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i:\n\u001b[1;32m--> 841\u001b[0m     found \u001b[38;5;241m=\u001b[39m \u001b[43mstrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m found:\n\u001b[0;32m    843\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(found)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\bs4\\element.py:2325\u001b[0m, in \u001b[0;36mSoupStrainer.search\u001b[1;34m(self, markup)\u001b[0m\n\u001b[0;32m   2323\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(markup, Tag):\n\u001b[0;32m   2324\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstring \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs:\n\u001b[1;32m-> 2325\u001b[0m         found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2326\u001b[0m \u001b[38;5;66;03m# If it's text, make sure the text matches.\u001b[39;00m\n\u001b[0;32m   2327\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(markup, NavigableString) \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[0;32m   2328\u001b[0m          \u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\bs4\\element.py:2288\u001b[0m, in \u001b[0;36mSoupStrainer.search_tag\u001b[1;34m(self, markup_name, markup_attrs)\u001b[0m\n\u001b[0;32m   2286\u001b[0m             markup_attr_map[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m   2287\u001b[0m attr_value \u001b[38;5;241m=\u001b[39m markup_attr_map\u001b[38;5;241m.\u001b[39mget(attr)\n\u001b[1;32m-> 2288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch_against\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   2289\u001b[0m     match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2290\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\bs4\\element.py:2356\u001b[0m, in \u001b[0;36mSoupStrainer._matches\u001b[1;34m(self, markup, match_against, already_tried)\u001b[0m\n\u001b[0;32m   2352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match_against \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   2353\u001b[0m     \u001b[38;5;66;03m# True matches any non-None value.\u001b[39;00m\n\u001b[0;32m   2354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m markup \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmatch_against\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCallable\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   2357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m match_against(markup)\n\u001b[0;32m   2359\u001b[0m \u001b[38;5;66;03m# Custom callables take the tag as an argument, but all\u001b[39;00m\n\u001b[0;32m   2360\u001b[0m \u001b[38;5;66;03m# other ways of matching match the tag name as a string.\u001b[39;00m\n",
      "File \u001b[1;32m<frozen abc>:117\u001b[0m, in \u001b[0;36m__instancecheck__\u001b[1;34m(cls, instance)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load and parse the HTML file\n",
    "html_file_path = '../../raw_data/lamunicipalcode.html'\n",
    "with open(html_file_path, 'r') as file:\n",
    "    soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "# Initialize lists to store data\n",
    "section_data = []\n",
    "subsection_data = []\n",
    "\n",
    "# Find all section divs\n",
    "section_divs = soup.find_all('div', class_='Section toc-destination rbox')\n",
    "\n",
    "# Process each section div\n",
    "for section_div in section_divs:\n",
    "    section_title = section_div.get_text(strip=True)\n",
    "    section_id = section_div.get('id', 'Unknown ID')\n",
    "\n",
    "    # Append section data\n",
    "    section_data.append({\n",
    "        'Section ID': section_id,\n",
    "        'Section Title': section_title\n",
    "    })\n",
    "\n",
    "    # Find all subsection divs within this section\n",
    "    for subsection_div in section_div.find_all_next('div', class_='rbox Normal-Level'):\n",
    "        subsection_text = subsection_div.find('div').get_text(strip=True)\n",
    "        subsection_number_match = re.match(r'\\([a-z]\\)\\s*', subsection_text)\n",
    "        \n",
    "        if subsection_number_match:\n",
    "            subsection_number = subsection_number_match.group().strip()\n",
    "            subsection_title = subsection_text[len(subsection_number):].strip()\n",
    "\n",
    "            # Append subsection data\n",
    "            subsection_data.append({\n",
    "                'Section ID': section_id,\n",
    "                'Subsection Number': subsection_number,\n",
    "                'Subsection Title': subsection_title\n",
    "            })\n",
    "\n",
    "# Convert section data to DataFrame and save as CSV\n",
    "section_df = pd.DataFrame(section_data)\n",
    "section_df.to_csv('../../intermediate_data/section_data.csv', header=True, index=False)\n",
    "\n",
    "# Convert subsection data to DataFrame and save as CSV\n",
    "subsection_df = pd.DataFrame(subsection_data)\n",
    "subsection_df.to_csv('../../intermediate_data/subsection_data.csv', header=True, index=False)\n",
    "\n",
    "# Print DataFrames to verify\n",
    "print(\"Sections DataFrame:\\n\", section_df)\n",
    "print(\"Subsections DataFrame:\\n\", subsection_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc8eae-8cab-4c03-82cd-578ed1264782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
