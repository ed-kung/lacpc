\section{Methodology}\label{sec_methodology}

We model the CPC hearings as having three possible outcomes:
\begin{enumerate}[start=0]
\item The project is denied or the decision is postponed;
\item The project is approved in part or with conditions or modifications;
\item The project is approved.
\end{enumerate}
Each project proposal $i$ is assumed to have a latent quality variable $y_i^\ast$ which determines the likelihood of the three outcomes. $y_i^\ast$ is modeled as a linear function of its observed project characteristics and bureaucratic factors, $\mathbf{X}_i$, plus an error term $\epsilon_i$:
\begin{align}
y_i^\ast = \mathbf{X}_i \beta + \epsilon_i
\end{align}
The latent quality of the project proposal determines its outcome at the CPC hearing. Let $y_{i} \in \{0, 1, 2\}$ denote project $i$'s outcome. The relationship between $y_i^\ast$ and $y_i$ is as follows:
\begin{align}
y_i = \begin{cases}
0 \text{ if } y_i^\ast < \mu_0 \\
1 \text{ if } \mu_0 \leq y_i^\ast < \mu_1 \\
2 \text{ if } \mu_1 \leq y_i^\ast
\end{cases}
\end{align}
with $\mu_0 < \mu_1$. The model is therefore an ordered logit model, and the outcomes are monotonic in $\mathbf{X}_i \beta$. The parameters $\beta$, $\mu_0$, and $\mu_1$ are estimated by maximum likelihood.

\subsection{Explanatory Variables}

We now turn to discussing the explanatory variables we include in the model.

\paragraph{Semantic uniqueness.} In that one of our goals is to quantify the role of bureaucratic frictions in the CPC approvals process, we here develop a concept which we call ``semantic uniqueness''. At a high level, semantic uniqueness is designed to capture how unique an agenda item is relative to other agenda items that the CPC is accustomed to facing. Our hypothesis is that agenda items which are highly unusual may be less likely to be approved, and more likely to be approved with conditions or denied or delayed. We thus expect to estimate a negative coefficient on semantic uniqueness.

To compute a measure of semantic uniqueness, we first calculate the semantic embedding of each agenda item using OpenAI's \texttt{text-embedding-3-small} embeddings model.\footnote{For an introduction to the concept of embeddings, see \citet{mikolov2013} and \citet{le2014}.} For each agenda item, the model returns a 1,536 dimensional numerical vector that represents the semantic meaning of the text. Two agenda items with very similar proposals will have embeddings that are close to each other, while two agenda items with very different proposals will have embeddings that are far away from each other. 

Because \texttt{text-embedding-3-small} was trained on a general corpus of documents, not specialized to the topic of municipal planning and zoning, not all 1,536 dimensions may be relevant for capturing the important differences between our agenda items. We therefore use principal components analysis to extract the 10 linear combinations of these dimensions which explain the most variance in our corpus. Figure \ref{fig_scree_plot} shows the scree plot of the principal components analysis. By the 10th principal component, there are diminishing returns to including more components.

After reducing the embeddings down to 10 dimensions, we group the agenda items into three clusters using K-Means clustering. Identifying clusters in our data is important because the CPC handles many different types of cases, and the language used could be quite different across cases of differing types. For example, the language used in a case involving the demolition of a building followed by reconstruction of a multifamily building would be very different from the language used in a case involving the conditional use permit to operate a school. Thus, it only makes sense to measure semantic uniqueness within a set of cases of similar type.

Figure \ref{fig_clusters} shows a scatter plot of the agenda items according to their first two principal components, colored by cluster. Cluster 0, the largest cluster, consists mainly of proposals to build new buildings. Cluster 1 consists mainly of citywide code amendments and general or community plan updates that the CPC must approve. Cluster 2, the smallest cluster, consists primarily of conditional use permits (requests to utilize facilities for purposes not allowed by right within the zoning designation.)

To measure the semantic uniqueness of an agenda item, we calculate the Mahalanobis distance between the agenda item's 10-dimensional PCA-reduced embedding to its cluster's centroid. We chose the Mahalanobis distance because [Joe explain]. In the regressions, we normalize the measured semantic uniqueness to have mean 0 and a variance of 1 across all our agenda items.

In addition to including the Mahalanobis distance to the cluster centroid as a measure of semantic uniqueness, we also include fixed effects for each cluster. This allows each cluster to have a separate baseline probability distribution over outcomes.

\paragraph{Perplexity.} Semantic uniqueness measures how unusual a proposal is relative to other cases of similar type. In addition to that, we also try to measure how confusing or hard to understand a proposal is in general. To do this, we ask \texttt{gpt-4o} to summarize each agenda item, then we measure the perplexity of the response. In language models, perplexity is a measure of how uncertain the model is about its response. It is measured as the exponent of the response's cross-entropy  (i.e. the negative mean of the output tokens' conditional log probabilities.)\footnote{See \citet{jm2}.} A perplexity of 1 indicates that the model has no uncertainty about its output, while a higher perplexity means the model is more uncertain. As with semantic uniqueness, we normalize perplexity to have a mean of 0 and a variance of 1 before including it in the regressions.

\paragraph{Agenda order.} We also hypothesize that the order in which a case appears in the agenda may matter for its outcome. Note that we use the order in which the case appears in the agenda, not the order in which the case was discussed at the actual meeting. The committee chair has the ability to discuss agenda items out of order, and this may be endogenous to the meeting outcomes, so we focus on the order in which the item appears in the agenda published prior to the start of the meeting.

\paragraph{Number of agenda items.} We hypothesize that the number of items on the agenda can have an effect on outcomes. In particular, we hypothesize that a case is more likely to be postponed if there are a large number of items on the agenda.

\paragraph{Consent calendar.} The Los Angeles CPC utilizes a practice for streamlining meetings known as the ``consent calendar''. The consent calendar takes multiple agenda items and groups them into a single motion that the committee votes on together as a whole. The consent calendar tends to include cases that the committee chair has deemed non-controversial and therefore not requiring separate discussion. The consent calendar is published \emph{before} the meeting starts, and items can be taken off the consent calendar during the meeting. We hypothesize that being on the consent calendar before the meeting starts significantly predicts approval.

\paragraph{Number of support and opposition letters.} We hypothesize that the amount of public support or public opposition matters for hearing outcomes. We hypothesize that more public support improves a proposal's probability of being approved, while more public opposition increases the likelihood that the proposal is denied, delayed, or approved with modifications. We include public support and public opposition as two separate explanatory variables to allow for heterogeneous impacts of support vs. opposition. We measure public support as the log base 2 of the number of letters written in support, and we measure public opposition as the log base 2 of the number of letters written in opposition, as discussed in Section \ref{sec_data}. Figure \ref{fig_support_oppose} shows the distribution of the number of letters in support and in opposition across cases. 

\paragraph{Council districts.} Council districts may matter for case outcomes for a variety of reasons. For one, although City Planning Commission members are appointed from a variety of professional backgrounds, most of them come from backgrounds of urban planning, public service, real estate development, or community advocacy. In all these cases, the member, despite best efforts to remain impartial, may still be influenced by the specific politics of the council district. For another, the Los Angeles City Council has veto power over City Planning Commission decisions, and in such decisions the council members usually defer to the opinion of the member in charge of the district that the project is located in. The CPC's decisions on a project could therefore be influenced by the opinions of the City Council member in charge of the district the project is located in. To control for these possibilities, we include council district fixed effects as explanatory variables.

\paragraph{Case suffixes.} As discussed in Section \ref{sec_data}, case suffixes indicate the types of entitlements requested or required by the project. In the raw dataset, there were over 70 unique case suffixes, which is too many dummy variables to include in a dataset with only \gn{NumberOfCases} observations. We therefore group the suffixes into XX groups, and include fixed effects for each of these suffix groups. The suffix groups are as follows:
\begin{enumerate}
\item suffix group 1
\item suffix group 2
\end{enumerate}
[Joe fill out]









